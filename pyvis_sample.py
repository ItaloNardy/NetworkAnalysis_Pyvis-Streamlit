# -*- coding: utf-8 -*-
"""pyvis_sample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/napoles-uach/streamlit_network/blob/main/pyvis_sample.ipynb
"""

!pip install pyvis
!pip install wikipedia


from operator import itemgetter
import networkx as nx
import wikipedia
import matplotlib.pyplot as plt
import seaborn as sns


nx.__version__

SEED = "Complex network".title()
STOPS = ("International Standard Serial Number",
         "International Standard Book Number",
         "National Diet Library",
         "International Standard Name Identifier",
         "International Standard Book Number (Identifier)",
         "Pubmed Identifier",
         "Pubmed Central",
         "Digital Object Identifier",
         "Arxiv",
         "Proc Natl Acad Sci Usa",
         "Bibcode",
         "Library Of Congress Control Number",
         "Jstor",
         "Doi (Identifier)",
         "Isbn (Identifier)",
         "Pmid (Identifier)",
         "Arxiv (Identifier)",
         "Bibcode (Identifier)")

todo_lst = [(0, SEED)] # The SEED is in the layer 0
todo_set = set(SEED) # The SEED itself
done_set = set() # Nothing is done yet

g = nx.DiGraph()
layer, page = todo_lst[0]

# Commented out IPython magic to ensure Python compatibility.
# %%time
# while layer < 2:
#   # Remove the name page of the current page from the todo_lst,
#   # and add it to the set of processed pages.
#   # If the script encounters this page again, it will skip over it.
#   del todo_lst[0]
#   done_set.add(page)
# 
#   # Show progress
#   print(layer, page)
# 
#   # Attempt to download the selected page.
#   try:
#     wiki = wikipedia.page(page)
#   except:
#     print("Could not load", page)
#     layer, page = todo_lst[0]
#     continue
# 
#   for link in wiki.links:
#     link = link.title()
#     if link not in STOPS and not link.startswith("List Of"):
#       if link not in todo_set and link not in done_set:
#         todo_lst.append((layer + 1, link))
#         todo_set.add(link)
#       g.add_edge(page, link)
#   layer, page = todo_lst[0]
# 
# 
# print("{} nodes, {} edges".format(len(g), nx.number_of_edges(g)))

print("{} nodes, {} edges".format(len(g), nx.number_of_edges(g)))

page = 'Complex network'.title()
wiki = wikipedia.page(page)
len(wiki.links)

# make a copy of raw graph
original = g.copy()

# remove self loops
g.remove_edges_from(nx.selfloop_edges(g))

# identify duplicates like that: 'network' and 'networks'
duplicates = [(node, node + "s")
              for node in g if node + "s" in g
             ]

for dup in duplicates:
  # *dup is a technique named 'unpacking'
  g = nx.contracted_nodes(g, *dup, self_loops=False)

print(duplicates)

duplicates = [(x, y) for x, y in
              [(node, node.replace("-", " ")) for node in g]
                if x != y and y in g]
print(duplicates)

for dup in duplicates:
  g = nx.contracted_nodes(g, *dup, self_loops=False)

# nx.contracted creates a new node/edge attribute called contraction
# the value of the attribute is a dictionary, but GraphML
# does not support dictionary attributes
nx.set_node_attributes(g, 0,"contraction")
nx.set_edge_attributes(g, 0,"contraction")

print("{} nodes, {} edges".format(len(g), nx.number_of_edges(g)))

degree = [drg for node , drg in g.degree()]
print(f'Max degree : {max(degree)}' )
print(f'Min degree : {min(degree)}' )

#filter nodes with degree greater than 12
#core decompo = 12
core = [node for node, drg in dict(g.degree()).items() if drg > 180 ] # 60 = 100 nodes / 180 = 50 nodes
degrees = [drg for node, drg in dict(g.degree()).items() if drg > 180 ] # 60 = 100 nodes / 180 = 50 nodes

subgraf_g = nx.subgraph(g,core)
print(f'Nodes: {len(subgraf_g)} edges: {nx.number_of_edges(subgraf_g)}')
nx.write_graphml(subgraf_g, "network_analysis.graphml")

print("Nodes removed: {:.2f}%".format(100*(1 - len(subgraf_g)/len(g))))
print("Edges removed: {:.2f}%".format(100*(1 - nx.number_of_edges(subgraf_g)/nx.number_of_edges(g))))
print("Original Average of edges by node: {:.2f}".format(nx.number_of_edges(g)/len(g)))
print("Subgraph Average of edges by node: {:.2f}".format(nx.number_of_edges(subgraf_g)/len(subgraf_g)))

from pyvis import network as net
g=net.Network(height='400px', width='50%',heading='', notebook=True, cdn_resources='remote')
g.add_node(1)
g.add_node(2)
g.add_node(3)
g.add_edge(1,2)
g.add_edge(2,3)
g = net.Network(height='400px', width='50%',heading='', directed=True, notebook=True, cdn_resources='remote')
g.from_nx(subgraf_g)
g.repulsion()
g.show_buttons(filter_=['physics'])
g.show('example.html')
from IPython.core.display import display, HTML
display(HTML('example.html'))

"""#END"""